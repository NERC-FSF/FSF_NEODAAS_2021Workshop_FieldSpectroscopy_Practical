{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NERC FSF -- Online Workshop\n",
    "\n",
    "## Stated Aims\n",
    "\n",
    "This notebook will take you through the steps of visualising data from a field spectrometer and turning it into a spectral\n",
    "library to use for image classification.  The data here is was collected on the 17th September 2020 at Dryden Farm. \n",
    "Spectra were recorded of the different end members in the field: soil \"soiltrue\", cut barley stubble \"brashes\", vegetation that was growing through the planted rows of barley as weeds \"vegetation\", and moss \"mosspatches\". In your file explorer, open the \"Photos\" folder to see a photo of each scene captured by the field spectrometer.\n",
    "\n",
    "## Introduction to Python\n",
    "\n",
    "Python is a computing language that is extensively used in the scientific community. While it may not be as effective for computationally demanding tasks as some other languages, such as C or Mathematica, its open source nature, large number of freely available and easy to install modules, and clear, easy to understand syntax, make it ideal for entry level (and beyond) scientific computing. \n",
    "In particular, **the Jupyter Notebook**, developed by Project Jupyter, is an excellent tool for both learning and demonstrating Python. Jupyter Notebooks are made up of **cells**, small snippets of code that can be run consecutively, allowing you to develop -- and to understand -- Python scripts. We'll be using it to teach you more about Python and its use in the processing of field spectroscopy data.\n",
    "\n",
    "## Using on your own data\n",
    "\n",
    "This workbook is designed such that you can paste your own data into the \"data\" folder and run through the processing with minimal modification. If you would like assistance in doing this in the future please email us at fsf@nerc.ac.uk\n",
    "\n",
    "\n",
    "### First Steps -- Importing Modules\n",
    "\n",
    "The first stage in any workflow in Python is to import the modules (which are collections of functions) that you will be using. In this analysis, we import a number of modules, the function of which is described in the comments (the light cyan text prefixed by the hash symbol). Note, modules must be installed first before use -- this can be handled by the **conda** package manager, or the **pip** package manager (please get in touch with us if you require help in setting this up). Here, the most important module to note is **SpecDAL**, a module designed to handle and process field spectroscopy data. To run the cell, **press Shift and ENTER**, or press **Run** in the ribbon above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/NERC-FSF/FieldSpecUtils.git -U\n",
    "import os    #a module that allows us to \"talk\" with our operating system, neccessary for handling paths, files and so on\n",
    "from pathlib import Path #a more specific path handling module that allows us to quickly create path names\n",
    "from specdal import Collection, Spectrum, read #We import our main package, specdal, and ask to only import certain key functions\n",
    "import pandas as pd   #Pandas is a powerful module for the handling of data sets\n",
    "from matplotlib import pyplot as plt   #matplotlib emulates the functions of MATLAB. Here, we tell matplotlib to only import one of it's functions, the pyplot function, and to import it with the identifier 'plt'\n",
    "from matplotlib.pyplot import ylabel, xlabel, title, legend   #We go even further by asking pyplot to only import some of it's subfunctions\n",
    "from scipy.signal import savgol_filter   #We will use this to smooth our data\n",
    "import numpy as np #We require numpy for integration functions that will be used during convolution\n",
    "import shutil #A clean up utility to remove files at the end of our session \n",
    "import FieldSpecUtils #NERC FSF utilities for the derivation of vegetiation indices and convultion of hyperspectral data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n",
    "Knowing where your data is located is naturally critical for processing. For this tutorial, your data folder containing you raw .sig files (**Data**) has been bundled along with the Notebook.  \n",
    "In the cell below, we set the **path** to the data folder, using the os module's inbuilt functions.\n",
    "Check the printed output here to make sure that this is the correct path to your .sig files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "Home_Dir = cwd\n",
    "Data_Dir = cwd / \"Data\" #The sub-directory where our .sig files are located\n",
    "csv_Dir = str(cwd / \"csv\") #The sub-directory which will store generated .csv files which at the end of our workshop will be deleted \n",
    "os.mkdir(csv_Dir) #We create the sub directory using the path names generated above, starting with \"csv_Dir\"\n",
    "print(Home_Dir)\n",
    "print(Data_Dir)\n",
    "print(csv_Dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpecDAL\n",
    "We will now use the SpecDAL package to read our .sig files, and assign them to a collection of spectra which we can analyse and process further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrydenEndMembers = Collection(name='DrydenEndMEmbers', directory ='Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at this spectra collection. First of all, let's have a look at the header information for the\n",
    "first 10 spectra in our collection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(DrydenEndMembers.spectra))\n",
    "for s in DrydenEndMembers.spectra[0:10]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a visual look at the data too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrydenEndMembers.plot(figsize=(15, 6), legend = True, ylim=(0,1), xlim=(350, 2500))\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Relative Reflectance\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Data \n",
    "It can be difficult to assess your data by viewing all spectra at once. \n",
    "We will group the data based on the vegetation type using SpecDAL's groupby function. \n",
    "This groups data based on their file names, in this case the name before the \"_\" separator e.g. \"grass\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = DrydenEndMembers.groupby(separator='.', indices=[0])\n",
    "group_names = list(groups.keys())\n",
    "print(group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now limit our graph to show only one vegetation type. Run this cell, then change **'Brashes'** to another one of the group names to plot that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "groups['Brashes'].plot(figsize=(15, 6), legend = True, ylim=(0,1), xlim=(350, 2500))\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Relative Reflectance\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then average each of these groups to produce a collection of means, called \"Species_means\". We will be returning to this collection later on, but for now, let's continue to look at individual spectra..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Species_means = Collection(name='Species_means')\n",
    "for group_key, group_collection in groups.items():\n",
    "    Species_means.append(group_collection.mean())\n",
    "\n",
    "Species_means.plot(title='Group means', figsize=(15, 6), ylim=(0, 1),xlim=(350, 2500))\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Relative Spectral Reflectance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've had a look at the data, we can do some preprocessing\n",
    "\n",
    "**THE NEXT SECTION GOES THROUGH SOME PREPROCESSING STEPS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "\n",
    "Notice that the steps between the wavelengths correspond to the spectral resolution of the instrument.\n",
    "We want to interpolate reflectance measurements that correspond to wavelengths with 1.0 nm spacing.\n",
    "This can be done using specdal as follows -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DrydenEndMembers.interpolate(spacing=1, method='linear')\n",
    "print(type(DrydenEndMembers.spectra))\n",
    "for s in DrydenEndMembers.spectra[0:5]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Relative vs Absolute Reflectance\n",
    "Notice from our previous graphs that the y-axes are labelled \"Relative Reflectance\". This is because these spectra were recorded relative to the reflectance of the white Spectralon panel. We take measurements relative to this panel to approximate the total irradiance coming from the sun and hitting the object you are interested in taking a spectral measurement of. Because the panel does not reflect 100% of the light that hits it in a completely uniform manner we need to adjust our  \"Relative Reflectance\" measurements using the panel's known, laboratory calibrated reflectance to convert our field measurements to absolute reflectance.\n",
    "\n",
    "We can derive the absolute reflectance then by multiplying our field measurements by the spectral reflectance of the panel for each wavelength. We can use this file to convert our measurements as follows. We are creating new dataframes that will host the corrected values, but the original dataframe can be corrected without having to assign a new identifier! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_panel = pd.read_csv((os.path.join(cwd, \"SRT_44.csv\")), index_col = \"wavelength\") \n",
    "AbsoluteRef_DrydenEM = DrydenEndMembers.data.mul(reference_panel['Reflectance'], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare a few of the relative reflectance spectra, in the dataframe **DrydenEndMembers**, with their corresponding, corrected spectra in **AbsoluteRef_DrydenEM**.  We can achieve this by calling specific columns in our uncorrected and corrected dataframes, concatenating them, and then comparing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Relative = DrydenEndMembers.data[['Brashes.0000_moc', 'MossPatches.0000_moc',\n",
    "                                  'soiltrue.0000_moc', 'vegetation.0000_moc' ]].copy().add_suffix('_Relative')\n",
    "\n",
    "Absolute = AbsoluteRef_DrydenEM[['Brashes.0000_moc', 'MossPatches.0000_moc',\n",
    "                                 'soiltrue.0000_moc', 'vegetation.0000_moc' ]].copy().add_suffix('_Absolute')\n",
    "\n",
    "\n",
    "Relative_vs_Absolute = pd.concat([Relative, Absolute], axis=1)\n",
    "\n",
    "Relative_vs_Absolute.head()\n",
    "Relative_vs_Absolute.plot(figsize=(12, 6), legend = True, ylim=(0.0,0.45), xlim=(350, 2500))\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Reflectance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing and Water Band Removal\n",
    "You may also notice a few noisy regions in the spectra. Can you see them?\n",
    "Let's zoom in around two regions in the Vegetation collection -- 1350 to 1460 nm, and 1790 to 1970 nm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsoluteRef_DrydenEM.plot(figsize=(8, 5), legend = None, ylim=(-1,1), xlim=(1300, 1500))\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Absolute Reflectance\")\n",
    "plt.show()\n",
    "\n",
    "AbsoluteRef_DrydenEM.plot(figsize=(8, 5), legend = None, ylim=(-1,1), xlim=(1750, 2000))\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Absolute Reflectance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These noisy regions are caused by the absorption of solar irradiance by water vapour in the atmopshere and can interfere with classification or use in indices. If the noise isn't too bad then smoothing may be suffcient to get rid of it, otherswise we will need to remove the noisy regions. Let's smooth our data set using a Savitsky-Golay filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsoluteRef_DrydenEM.to_csv(csv_Dir + \"/\" + r'AntarcticVeg_AbsRef.csv')\n",
    "AbsRef_Smoothing_DrydenEM = pd.read_csv(csv_Dir + \"/\" + r'AntarcticVeg_AbsRef.csv', index_col=0, header=0)\n",
    "AbsRef_Smoothing_DrydenEM.drop(AbsRef_Smoothing_DrydenEM.index[0:9], inplace = True)\n",
    "AbsRef_Smoothing_DrydenEM.drop(AbsRef_Smoothing_DrydenEM.index[2151:], inplace = True)\n",
    "AbsRef_Smoothing_DrydenEM_smoothed = pd.DataFrame(savgol_filter(AbsRef_Smoothing_DrydenEM, 41, 2, axis=0),\n",
    "                                columns=AbsRef_Smoothing_DrydenEM.columns,\n",
    "                                index=AbsRef_Smoothing_DrydenEM.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how that changed things --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsRef_Smoothing_DrydenEM_smoothed.plot(figsize=(8, 5), legend = None, ylim=(-1,1), xlim=(1300, 1500))\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Absolute Reflectance\")\n",
    "plt.show()\n",
    "\n",
    "AbsRef_Smoothing_DrydenEM_smoothed.plot(figsize=(8, 5), legend = None, ylim=(-2,2), xlim=(1750, 2000))\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Absolute Reflectance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, smoothing has managed to remove most of the noise from the c. 1400nm water absorption feature, but not the one at c. 1900nm. Lets completely remove the water band at c. 1900nm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsRef_Smoothing_DrydenEM_smoothed.to_csv(csv_Dir + \"/\" + r'DrydenEM_AbsRef_WBRemoval.csv')\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM = pd.read_csv(csv_Dir + \"/\" + 'DrydenEM_AbsRef_WBRemoval.csv', index_col=0, header=0)\n",
    "#AbsRef_Smoothed_WBRemoved_DrydenEM.loc[1350:1460] = \"\" #this can be used if you need to remove noise @ 1400nm. \n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM.loc[1790:1970] = \"\"\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM.to_csv(csv_Dir + \"/\" + r'DrydenEM_AbsRef_WBRemoval.csv')\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM = pd.read_csv(csv_Dir + \"/\" + 'DrydenEM_AbsRef_WBRemoval.csv', index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now conduct the same operations on our averaged, grouped spectra. For simplicity, we will combine all operations in one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Species_means.interpolate(spacing=1, method='linear')\n",
    "AbsoluteRef_DrydenEM_groups = Species_means.data.mul(reference_panel['Reflectance'], axis = 0)\n",
    "\n",
    "AbsoluteRef_DrydenEM_groups.to_csv(csv_Dir + \"/\" + r'DrydenEM_AbsRef_Groups.csv')\n",
    "AbsRef_Smoothing_DrydenEM_groups = pd.read_csv(csv_Dir + \"/\" + r'DrydenEM_AbsRef_Groups.csv', index_col=0, header=0)\n",
    "AbsRef_Smoothing_DrydenEM_groups.drop(AbsRef_Smoothing_DrydenEM_groups.index[0:9], inplace = True)\n",
    "AbsRef_Smoothing_DrydenEM_groups.drop(AbsRef_Smoothing_DrydenEM_groups.index[2151:], inplace = True)\n",
    "AbsRef_Smoothing_DrydenEM_groups_smoothed = pd.DataFrame(savgol_filter(AbsRef_Smoothing_DrydenEM_groups, 41, 2, axis=0),\n",
    "                                columns=AbsRef_Smoothing_DrydenEM_groups.columns,\n",
    "                                index=AbsRef_Smoothing_DrydenEM_groups.index)\n",
    "\n",
    "\n",
    "AbsRef_Smoothing_DrydenEM_groups_smoothed.to_csv(csv_Dir + \"/\" + r'DrydenEM_AbsRef_WBRemoval_groups.csv')\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups = pd.read_csv(csv_Dir + \"/\" + 'DrydenEM_AbsRef_WBRemoval_groups.csv', index_col=0, header=0)\n",
    "#AbsRef_Smoothed_WBRemoved_DrydenEM_groups.loc[1350:1460] = \"\" #this can be used if you need to remove noise @ 1400nm. \n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups.loc[1790:1970] = \"\"\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups.to_csv(csv_Dir + \"/\" + r'DrydenEM_AbsRef_WBRemoval_groups.csv')\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups = pd.read_csv(csv_Dir + \"/\" + 'DrydenEM_AbsRef_WBRemoval_groups.csv', index_col=0, header=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export this collection to a .csv, which will act as our spectral library in further processing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups = AbsRef_Smoothed_WBRemoved_DrydenEM_groups.dropna()\n",
    "\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups.interpolate(method='linear', axis=0).ffill().bfill()\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups.to_csv(\"Mean_plot_spectra.csv\")\n",
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups.to_csv(r'Dryden_Spectral_Lib_SNAP.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how this spectral library looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsRef_Smoothed_WBRemoved_DrydenEM_groups.plot(figsize=(9, 6), legend = True, ylim=(0,1), xlim=(350, 2500))\n",
    "xlabel(\"Wavelength (nm)\")\n",
    "ylabel(\"Absolute Reflectance\")\n",
    "title(\"Mean absolute reflectance for Dryden Farm end members\")\n",
    "legend(title = \"Collection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vegetation Indices\n",
    "With your data now processed and converted into absolute spectral reflectance, we can look more closely at differences between vegetation types. We can use dimensionality reduction methods such as spectral indices \n",
    "\n",
    "https://fsf.nerc.ac.uk/resources/learning/HSI.shtml\n",
    "\n",
    "A number of spectral indices have been designed to highlight different vegetation properties. In this next section, we will use some of them to explore differences between our vegetation types. For a full description of the indices used, please visit: https://www.l3harrisgeospatial.com/docs/NarrowbandGreenness.html\n",
    "\n",
    "Firstly, let's import the **Vegetation_Indices** module from FSF's FieldSpecUtils module. \n",
    "**Vegetation_Indices** has a number of fucntions, which you can see by using **help(FieldSpecUtils.Vegetation_Indices)**. Each function has a description of the vegetation index it calculates. You can use the **help(\"module name\")** feature for other modules to find out more about them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from FieldSpecUtils import Vegetation_Indices\n",
    "help(\"FieldSpecUtils.Vegetation_Indices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this mind, let's calculate the Normalized Differential Vegetation Index for our individual and group spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a \"#\" to comment out individual or grouped data\n",
    "\n",
    "#Vegetation_Indices.RENDVI(AbsRef_Smoothed_WBRemoved_DrydenEM)\n",
    "Vegetation_Indices.RENDVI(AbsRef_Smoothed_WBRemoved_DrydenEM_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "If your research relates to specific multispectral imaging sensors e.g. Sentinel 2, it can be useful to resample \n",
    "your hyperspectral data so that it matches the bands of your specific sensor. \n",
    "We can do this by convolving the hyperspectral data to a multispectral sensor's \"spectral response function\". \n",
    "Read more on this here: HYPERELINK\n",
    "    \n",
    "We will be using this hyperspectral data to classify a Worldview 3 image \n",
    "https://earth.esa.int/eogateway/missions/worldview-3 \n",
    "So lets convolve our data so that it matches Worldview 3.\n",
    "\n",
    "To do this, we use another function in our FSF module called \"Convolution\". Let's import that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FieldSpecUtils import Convolution\n",
    "help(\"FieldSpecUtils.Convolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with **Vegetation_Indices**, you can find out more about the functions included in **Convolution** by typing **help(\"FieldSpecUtils.Convolution\")**. Notice the function **S2** and it's description. We will use **S2** to convolve our spectral library to Sentinel-2 bands. To do so, we import the spectral sesponse function for Sentinel-2, found in **Sentinel 2 SRF.csv**. It shows the relative response to specific wavelengths of light for each band of the imager.\n",
    "\n",
    "https://fsf.nerc.ac.uk/resources/learning/SRF.shtml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bands = pd.read_csv(\"Sentinel 2 SRF.csv\", index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convolution.S2(AbsRef_Smoothed_WBRemoved_DrydenEM_groups, Bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hyperspectral data has now been convolved to multispectral bands equivalent to Sentinel-2. We can see how this looks by plotting the data output of the convolution, **Ploths_with_convolved_bands.csv**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collated_convolved = pd.read_csv(\"Plots_with_convolved_bands.csv\", index_col = 0)\n",
    "collated_convolved.plot(figsize=(9, 6), legend = True, ylim=(0,1), linestyle='--', marker='o')\n",
    "xlabel(\"Centre Wavelength (nm) of Band with Band Number\")\n",
    "ylabel(\"Absolute Reflectance\")\n",
    "title(\"Hyperspectral convolved broadband reflectance\")\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "           [\"490 -- Band 2\", \"560 -- Band 3\", \"665 -- Band 4\", \"705 -- Band 5\", \"740 -- Band 6\",\n",
    "            \"783 -- Band 7\", \"842 -- Band 8\", \"865 -- Band 8a\", \"1610 -- Band 11\", \"2190 -- Band 12\"],\n",
    "           rotation=20)\n",
    "legend(title = \"Plot number and vegetation type\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Convolved_Hyperspectral_Plot_Data_to_S2_Multispectral_Bands.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Vegetation Indices using convolved data\n",
    "As our hyperpsectral data convolved to Sentinel-2 equivalent multispectral bands, we can also calculate a value for the Normalized Difference Vegetation Index using band values. For Sentinel-2 bands, NDVI can be calculated, according to https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/ndvi/, as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "NDVI = \\dfrac{B_8 - B_4}{B_8 + B_4}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where ${B_8}$ is Band 8 (centre wavelength = 842 nm) and ${B_4}$ is Band 4 (centre wavelength = 665). The cell below runs this equation using your convolved hyperspectral data, and appends the NDVI as a new row to your dataframe **collated_convolved**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collated_convolved.loc['NDVI'] = ((collated_convolved.loc['Band 8 - 842'] - collated_convolved.loc['Band 4 - 665']) / \n",
    "                                  (collated_convolved.loc['Band 8 - 842'] + collated_convolved.loc['Band 4 - 665'])) \n",
    "\n",
    "print(collated_convolved.loc['NDVI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a new data frame that will compare the NDVI values generated from the hyperspectral data and the same hyperspectral data, but convolved to multispectral data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Hyperspectral_NDVI = Vegetation_Indices.NDVI(AbsRef_Smoothed_WBRemoved_DrydenEM_groups)\n",
    "Hyperspectral_NDVI = Hyperspectral_NDVI.rename({'Brashes_mean': 'Brashes', 'MossPatches_mean': 'Moss Patches',\n",
    "                         'soiltrue_mean': 'Soil', 'vegetation_mean':'vegetation'})\n",
    "Hyperspectral_NDVI = Hyperspectral_NDVI.to_frame()\n",
    "Hyperspectral_NDVI = Hyperspectral_NDVI.rename(columns={0:\"NDVI_Hyperspectral\"})\n",
    "\n",
    "print(Hyperspectral_NDVI)\n",
    "\n",
    "Multispectral_NDVI = collated_convolved.loc['NDVI']\n",
    "Multispectral_NDVI = Multispectral_NDVI.rename(index={'Bands_Brashes_meanSRF': 'Brashes', 'Bands_MossPatches_meanSRF': 'Moss Patches',\n",
    "                         'Bands_soiltrue_meanSRF': 'Soil', 'Bands_vegetation_meanSRF':'vegetation'})\n",
    "Multispectral_NDVI = Multispectral_NDVI.to_frame()\n",
    "Multispectral_NDVI = Multispectral_NDVI.rename(columns={'NDVI':'NDVI_Multipectral'})\n",
    "print(Multispectral_NDVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NDVI_Comparison = pd.concat([Multispectral_NDVI, Hyperspectral_NDVI] ,axis = 1)\n",
    "print(NDVI_Comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our comparison collated into one data frame, we can now visually compare the two datasets by plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NDVI_Comparison.plot(figsize=(9, 6), legend = True, ylim=(0,1))\n",
    "xlabel(\"Vegetation Type\")\n",
    "ylabel(\"Absolute Reflectance\")\n",
    "title(\"Comaprison between NDVI acquired from \\n a. hyperspectral data and b. hyperspectral data convolved to mutlispectral\")\n",
    "legend(title = \"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"NDVI_Hyperspectral_vs_Multispectral.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional -- Cleaning the Work Directory\n",
    "We have generated a lot of .csv files for processing, as a means to illustrate the step-by-step procedure involved. These .csv files are now superflous. You may keep them if you wish, in which case, do not run this cell. If not, this cell will delete the csv folder containing these files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(csv_Dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: KEEP THIS WORKBOOK OPEN SO YOU CAN USE SOME OF THE INFORMATION IN THE NEXT PRACTICAL "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
